{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e615cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.26/08\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from DarkMatter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fee391db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def cash_stat(params, on_count, off_count, signal_count, alpha):\n",
    "    \"\"\"\n",
    "    Calculate Cash statistic (modified for profile likelihood)\n",
    "    \"\"\"\n",
    "    signal_scale, background_scale = params\n",
    "    signal_scale = 10**signal_scale\n",
    "    \n",
    "    model_on = signal_scale * signal_count + background_scale * off_count * alpha\n",
    "    model_off = background_scale * off_count\n",
    "    \n",
    "    # Cash statistic (Poisson likelihood function)\n",
    "    cash_on = model_on + on_count * np.log((on_count+1e-10) / (model_on+1e-10))\n",
    "    cash_off = model_off + off_count * np.log((off_count+1e-10) / (model_off+1e-10))\n",
    "    \n",
    "    return cash_on + cash_off\n",
    "\n",
    "def sum_cash_stat(params, on_counts, off_counts, signal_counts, alpha):\n",
    "    \"\"\"Sum Cash statistics across all bins\"\"\"\n",
    "    total_cash = 0\n",
    "    for on, off, signal in zip(on_counts, off_counts, signal_counts):\n",
    "        total_cash += cash_stat(params, on, off, signal, alpha)\n",
    "    return total_cash\n",
    "\n",
    "def fit_on_off_data(on_counts, off_counts, signal_counts, alpha):\n",
    "    \"\"\"Fit data using Cash statistic minimization\"\"\"\n",
    "    initial_params = [-1, 1.0]\n",
    "    bounds = [(-5, 5), (0.8, 1.2)]\n",
    "    \n",
    "    # Minimize negative log-likelihood\n",
    "    result = minimize(sum_cash_stat, initial_params, \n",
    "                     args=(on_counts, off_counts, signal_counts, alpha),\n",
    "                     method='L-BFGS-B', bounds=bounds)\n",
    "    \n",
    "    return result.x, result.fun\n",
    "\n",
    "def bin_by_bin_log_likelihood(signal_scales, on_count, off_count, signal_count, alpha, params):\n",
    "    \"\"\"\n",
    "    Calculate profile likelihood for different signal scales\n",
    "    Returns: Delta log-likelihood relative to best fit\n",
    "    \"\"\"\n",
    "    background_scale = params[1]\n",
    "    loglikelihood_profile = []\n",
    "    for scale in signal_scales:\n",
    "        # For each signal scale, optimize background\n",
    "        current_params = [scale, background_scale]\n",
    "        # Calculate log-likelihood\n",
    "        ll = -cash_stat(current_params, on_count, off_count, signal_count, alpha)\n",
    "        # Store delta log-likelihood\n",
    "        loglikelihood_profile.append((ll))\n",
    "\n",
    "        \n",
    "    subtracted = max(loglikelihood_profile)-loglikelihood_profile\n",
    "    aboveMax = (subtracted>min(subtracted))\n",
    "    st_idx = list(aboveMax).index(False)\n",
    "    intp = interp1d(subtracted[st_idx:], signal_scales[st_idx:])\n",
    "    \n",
    "    return subtracted, intp(1.35)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "def plot_likelihood_energy(ll_array, energy_flux):\n",
    "    \"\"\"\n",
    "    Plot energy flux upper limits aligned with likelihood profiles\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ll_array : dict\n",
    "        Dictionary with energy as key and array of [flux, likelihood] as values\n",
    "    energy_flux : array-like\n",
    "        Energy flux upper limit values\n",
    "    energies : array-like\n",
    "        Energy values\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Create mesh grid for likelihood plot\n",
    "    likelihood_mesh = []\n",
    "    flux_values = []\n",
    "    \n",
    "    # Extract first energy bin's flux values to determine the common flux grid\n",
    "    first_energy = list(ll_array.keys())[0]\n",
    "    n_flux_points = len(ll_array[first_energy])\n",
    "    energies = np.array(list(ll_array.keys()))\n",
    "    \n",
    "    # Collect likelihood profiles and flux values\n",
    "    for energy in energies:\n",
    "        if energy in ll_array:\n",
    "            data = ll_array[energy]\n",
    "            flux_values = data[:, 0]  # Flux values\n",
    "            likelihood_mesh.append(data[:, 1])  # Likelihood values\n",
    "    \n",
    "    likelihood_mesh = np.array(likelihood_mesh).T\n",
    "    # Mask likelihood values above 10\n",
    "    masked_likelihood = np.ma.masked_where(likelihood_mesh > 10, likelihood_mesh)\n",
    "    \n",
    "    # Plot likelihood profiles\n",
    "\n",
    "    im = ax1.pcolormesh(energies, flux_values, masked_likelihood,\n",
    "                        shading='auto', cmap='turbo',\n",
    "                        norm=mcolors.Normalize(vmin=0, vmax=10))\n",
    "\n",
    "    # Plot upper limits with arrows\n",
    "\n",
    "    log_energies = np.log10(energies)\n",
    "    bin_width = log_energies[1] - log_energies[0]  # Width in log space\n",
    "    xerr = np.array([energies * (1 - 10**(-bin_width/2)), \n",
    "                     energies * (10**(bin_width/2) - 1)])\n",
    "    \n",
    "    # Plot upper limits with errorbars\n",
    "    ax1.errorbar(energies, energy_flux, \n",
    "                xerr=xerr,\n",
    "                yerr=0.2 * energy_flux,  # 20% error bar length\n",
    "                uplims=True,\n",
    "                fmt='k.',\n",
    "                markersize=8,\n",
    "                capsize=3,\n",
    "                label='95% C.L. Upper Limits')\n",
    "    \n",
    "    # Set axes scales and limits\n",
    "    ax1.set_xscale('log')\n",
    "    ax1.set_yscale('log')\n",
    "\n",
    "    \n",
    "    # Labels and formatting\n",
    "    ax1.set_ylabel(r'Flux (GeV/cm$^2$/s)', fontsize=12)\n",
    "    ax1.set_xlabel('Energy (GeV)')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax1)\n",
    "    cbar.set_label('Î” log L', fontsize=12)\n",
    "        \n",
    "    ax1.set_ylim(1e-11, 1e-7)\n",
    "    return ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47369b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dwarf in const.ListOfDwarf:\n",
    "    On, Off = EventDisplay.readData(dwarf, ext=True, apply_weight=False)\n",
    "    rawData = EventDisplay.readData(dwarf, ext=True, rawdata=True)\n",
    "    irf = ResponseFunction.EventDisplay.readIRFs(dwarf, ext=True)\n",
    "    Signal = combinedCalcSignal(dwarf, 1e4, DM_spectra=\"powerlaw\", irf=irf, ext=True, eLowerCut=min(rawData[:,0]))\n",
    "    combined_pars, loglikelihood = fit_on_off_data(getArray(On)[1], getArray(Off)[1], getArray(Signal)[1], alpha=1/6.)\n",
    "\n",
    "    ll_array = {}\n",
    "    best_norms = []\n",
    "    energies = []\n",
    "    ll_array_plot = []\n",
    "    for i, eng in enumerate(getArray(Off)[0]):\n",
    "        try:\n",
    "            ll, norm = bin_by_bin_log_likelihood(np.linspace(-3, 3, 100), \n",
    "                                                   getArray(On)[1][i], \n",
    "                                                   getArray(Off)[1][i], \n",
    "                                                   getArray(Signal)[1][i], \n",
    "                                                   1/6., combined_pars)\n",
    "        except:\n",
    "            continue\n",
    "        ll_array[eng] = np.asarray([eng**2*(eng/1e3)**-2*1e-23*1e7*10**np.linspace(-3, 3, 100), ll]).T\n",
    "\n",
    "        best_norms.append(norm)\n",
    "        energies.append(eng)\n",
    "\n",
    "    best_norms = np.asarray(best_norms)\n",
    "    energies = np.asarray(energies)\n",
    "\n",
    "    energyflux = []\n",
    "    for energy, par in zip(getArray(Signal)[0], best_norms):\n",
    "        energyflux.append(energy**2*(energy/1e3)**-2*1e-23*1e7*10**par)\n",
    "    energyflux = np.asarray(energyflux)\n",
    "\n",
    "    np.save(f\"{dwarf}_energy_flux\", np.asarray([energies, energyflux]).T)\n",
    "    np.save(f\"{dwarf}_likelihood\", ll_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1427817",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwarf = \"UMa_III\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "On, Off = EventDisplay.readData(dwarf, ext=True, apply_weight=False)\n",
    "rawData = EventDisplay.readData(dwarf, ext=True, rawdata=True)\n",
    "irf = ResponseFunction.EventDisplay.readIRFs(dwarf, ext=True)\n",
    "Signal = combinedCalcSignal(dwarf, 1e4, DM_spectra=\"powerlaw\", irf=irf, ext=True, eLowerCut=min(rawData[:,0]))\n",
    "combined_pars, loglikelihood = fit_on_off_data(getArray(On)[1], getArray(Off)[1], getArray(Signal)[1], alpha=1/6.)\n",
    "\n",
    "ll_array = {}\n",
    "best_norms = []\n",
    "energies = []\n",
    "ll_array_plot = []\n",
    "for i, eng in enumerate(getArray(Off)[0]):\n",
    "    try:\n",
    "        ll, norm = bin_by_bin_log_likelihood(np.linspace(-3, 3, 100), \n",
    "                                               getArray(On)[1][i], \n",
    "                                               getArray(Off)[1][i], \n",
    "                                               getArray(Signal)[1][i], \n",
    "                                               1/6., combined_pars)\n",
    "    except:\n",
    "        continue\n",
    "    ll_array[eng] = np.asarray([eng**2*(eng/1e3)**-2*1e-23*1e7*10**np.linspace(-3, 3, 100), ll]).T\n",
    "\n",
    "    best_norms.append(norm)\n",
    "    energies.append(eng)\n",
    "\n",
    "best_norms = np.asarray(best_norms)\n",
    "energies = np.asarray(energies)\n",
    "\n",
    "energyflux = []\n",
    "for energy, par in zip(getArray(Signal)[0], best_norms):\n",
    "    energyflux.append(energy**2*(energy/1e3)**-2*1e-23*1e7*10**par)\n",
    "energyflux = np.asarray(energyflux)\n",
    "\n",
    "np.save(f\"{dwarf}_energy_flux\", np.asarray([energies, energyflux]).T)\n",
    "np.save(f\"{dwarf}_likelihood\", ll_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23abe9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
